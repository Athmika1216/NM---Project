import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
import os

# Load dataset (you can download from Kaggle or use a CSV with 'text' and 'label' columns)
def load_dataset(path='fake_or_real_news.csv'):
    if not os.path.exists(path):
        raise FileNotFoundError("Dataset file not found. Please add 'fake_or_real_news.csv'.")
    df = pd.read_csv(path)
    df = df[['text', 'label']]
    df.dropna(inplace=True)
    df['label'] = df['label'].map({'REAL': 1, 'FAKE': 0})
    return df

# Preprocess and save TF-IDF vectorizer and model-ready datasets
def prepare_dataset(path='fake_or_real_news.csv'):
    df = load_dataset(path)

    X = df['text']
    y = df['label']

    # TF-IDF vectorization
    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
    X_vect = vectorizer.fit_transform(X)

    # Save vectorizer
    joblib.dump(vectorizer, 'vectorizer.pkl')

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

if _name_ == "_main_":
    X_train, X_test, y_train, y_test = prepare_dataset()
    print("Dataset loaded and processed. Ready for training.")